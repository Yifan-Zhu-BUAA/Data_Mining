\documentclass[12pt,a4paper]{article}
\usepackage[UTF8]{ctex}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{float}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{booktabs}
\usepackage{geometry}
\geometry{left=2.5cm,right=2.5cm,top=2.5cm,bottom=2.5cm}

% 代码样式设置
\lstset{
    language=Python,
    basicstyle=\ttfamily\small,
    keywordstyle=\color{blue},
    commentstyle=\color{green!60!black},
    stringstyle=\color{red},
    numbers=left,
    numberstyle=\tiny\color{gray},
    stepnumber=1,
    numbersep=5pt,
    backgroundcolor=\color{gray!10},
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    frame=single,
    rulecolor=\color{black},
    tabsize=2,
    captionpos=b,
    breaklines=true,
    breakatwhitespace=false,
    escapeinside={\%*}{*)}
}

\title{图像异常检测任务报告}
\author{数据挖掘课程作业}
\date{\today}

\begin{document}

\maketitle

\tableofcontents
\newpage

\section{问题形式化描述}

\subsection{问题定义}

图像异常检测是一种无监督或半监督学习任务，目标是识别出与正常样本分布显著不同的异常样本。在本任务中，我们处理的是单类别异常检测问题，具体定义如下：

给定一个包含正常样本和异常样本的图像数据集 $\mathcal{D} = \mathcal{D}_{normal} \cup \mathcal{D}_{anomaly}$，其中 $\mathcal{D}_{normal}$ 是正常样本集合，$\mathcal{D}_{anomaly}$ 是异常样本集合。我们的目标是训练一个模型，该模型能够：

\begin{itemize}
    \item 从正常样本中学习数据的潜在分布
    \item 对未知样本进行评估，判断其是否为异常
    \item 尽可能准确地区分正常样本和异常样本
\end{itemize}

\subsection{数学形式化}

设训练集仅包含正常样本 $\mathcal{D}_{train} = \{x_1, x_2, \ldots, x_n\}$，其中 $x_i$ 是正常图像。我们训练一个重构模型 $f: \mathcal{X} \rightarrow \mathcal{X}$，该模型尝试将输入图像 $x$ 重构为 $\hat{x} = f(x)$。

对于测试样本 $y$，我们计算其重构误差作为异常分数：

\begin{equation}
	ext{anomaly\_score}(y) = d(y, f(y))
\end{equation}

其中 $d(\cdot, \cdot)$ 是某种距离度量（如MSE、MAE等）。

设定一个阈值 $	au$，如果异常分数大于 $	au$，则将样本判定为异常，否则判定为正常：

\begin{equation}
	ext{prediction}(y) = \begin{cases} 
	ext{anomaly}, & 	ext{if } 	ext{anomaly\_score}(y) > \tau \\ 
	ext{normal}, & 	ext{otherwise} 
\end{cases}
\end{equation}

\subsection{数据集描述}

本任务使用的图像异常检测数据集包含以下信息：
\begin{itemize}
    \item \textbf{类别数量}：2个类别（hazelnut（榛子）和zipper（拉链））
    \item \textbf{训练集}：每个类别包含200张正常样本和50张异常样本
    \item \textbf{测试集}：包含正常样本和异常样本
    \item \textbf{图像格式}：PNG格式
\end{itemize}

\subsection{异常定义}

在本数据集中：
\begin{enumerate}
    \item \textbf{hazelnut（榛子）}：
    \begin{itemize}
        \item 正常样本：完整、无缺陷的榛子图像
        \item 异常样本：有孔洞、裂缝或其他缺陷的榛子图像
    \end{itemize}
    \item \textbf{zipper（拉链）}：
    \begin{itemize}
        \item 正常样本：排列整齐、无损坏的拉链图像
        \item 异常样本：链条错位、损坏或变形的拉链图像
    \end{itemize}
\end{enumerate}

\section{图像特征处理}

\subsection{数据预处理}

在异常检测任务中，数据预处理是非常重要的一步。我们采用以下预处理步骤：

\begin{enumerate}
    \item \textbf{图像调整大小}：将所有图像调整为统一大小（例如 $224 \times 224$ 或 $128 \times 128$）
    \item \textbf{归一化}：将像素值缩放到 $[0, 1]$ 范围内
    \item \textbf{数据增强（可选）}：对训练集应用旋转、翻转等增强操作，提高模型的泛化能力
    \item \textbf{数据分割}：将训练数据进一步划分为训练集和验证集
\end{enumerate}

\subsection{特征表示}

在本任务中，我们采用深度学习方法自动学习图像的特征表示，而不是手动设计特征。具体来说：

\begin{itemize}
    \item 我们使用自编码器（Autoencoder）作为特征学习模型
    \item 编码器部分将输入图像映射到低维潜在空间
    \item 解码器部分尝试从潜在表示重构原始图像
    \item 模型通过最小化重构误差来学习数据的有效表示
\end{itemize}

\section{异常检测模型}

\subsection{模型概述}

本任务实现了两种自编码器模型用于图像异常检测：

\subsubsection{基础自编码器（Autoencoder）}

基础自编码器由编码器和解码器两部分组成：

\begin{enumerate}
    \item \textbf{编码器（Encoder）}：
    \begin{itemize}
        \item 输入：原始图像
        \item 结构：4个卷积块，每个卷积块包含卷积层、批量归一化层和ReLU激活函数
        \item 输出：低维潜在表示
    \end{itemize}
    \item \textbf{解码器（Decoder）}：
    \begin{itemize}
        \item 输入：潜在表示
        \item 结构：4个反卷积块，每个反卷积块包含反卷积层、批量归一化层和ReLU激活函数
        \item 输出：重构图像（使用Sigmoid激活函数确保输出在$[0, 1]$范围内）
    \end{itemize}
\end{enumerate}

\textbf{损失函数}：均方误差（MSE）
\begin{equation}
L(x, \hat{x}) = \frac{1}{H \times W \times C} \sum_{i=1}^{H} \sum_{j=1}^{W} \sum_{k=1}^{C} (x_{ijk} - \hat{x}_{ijk})^2
\end{equation}

\subsubsection{变分自编码器（Variational Autoencoder, VAE）}

变分自编码器是基础自编码器的扩展，引入了概率建模思想：

\begin{enumerate}
    \item \textbf{编码器}：
    \begin{itemize}
        \item 输入：原始图像
        \item 输出：潜在空间中的均值向量 $\mu$ 和对数方差向量 $\log \sigma^2$
    \end{itemize}
    \item \textbf{重参数化技巧}：
    \begin{itemize}
        \item 通过采样获得潜在表示：$z = \mu + \sigma \times \epsilon$，其中 $\epsilon \sim \mathcal{N}(0, I)$
    \end{itemize}
    \item \textbf{解码器}：
    \begin{itemize}
        \item 输入：潜在表示 $z$
        \item 输出：重构图像
    \end{itemize}
\end{enumerate}

\textbf{损失函数}：组合重构损失和KL散度
\begin{equation}
L(x, \hat{x}, \mu, \sigma^2) = L_{MSE}(x, \hat{x}) + \beta \times D_{KL}(q(z|x) || p(z))
\end{equation}

其中：
\begin{itemize}
    \item $L_{MSE}$ 是均方误差重构损失
    \item $D_{KL}$ 是KL散度，衡量潜在分布与标准正态分布的差异
    \item $\beta$ 是控制KL散度权重的超参数
\end{itemize}

\subsection{训练策略}

我们采用以下训练策略：

\begin{enumerate}
    \item \textbf{数据使用}：仅使用正常样本进行训练
    \item \textbf{优化器}：Adam优化器，学习率设置为 $1e-4$
    \item \textbf{批量大小}：32或64
    \item \textbf{早停机制}：当验证集上的重构损失不再下降时停止训练，防止过拟合
    \item \textbf{模型保存}：保存验证集上表现最好的模型
\end{enumerate}

\subsection{异常检测策略}

异常检测的核心是确定合适的阈值。我们采用以下策略：

\begin{enumerate}
    \item 在验证集（仅包含正常样本）上计算所有样本的重构误差
    \item 选择一个阈值，使得在验证集上的假阳性率控制在可接受范围内
    \item 或者，使用精确率-召回率曲线，选择F1分数最高的阈值
    \item 对于测试样本，计算其重构误差，如果超过阈值则判定为异常
\end{enumerate}

\section{异常检测效果评估}

\subsection{评估指标}

我们使用以下指标来评估异常检测模型的性能：

\subsubsection{二分类评估指标}

\begin{enumerate}
    \item \textbf{精确率（Precision）}：
    \begin{equation}
    Precision = \frac{TP}{TP + FP}
    \end{equation}
    其中TP是真正例（正确检测出的异常样本），FP是假正例（将正常样本错误地检测为异常）。
    
    \item \textbf{召回率（Recall）}：
    \begin{equation}
    Recall = \frac{TP}{TP + FN}
    \end{equation}
    其中FN是假负例（将异常样本错误地检测为正常）。
    
    \item \textbf{F1分数}：
    \begin{equation}
    F1 = \frac{2 \times Precision \times Recall}{Precision + Recall}
    \end{equation}
    
    \item \textbf{准确率（Accuracy）}：
    \begin{equation}
    Accuracy = \frac{TP + TN}{TP + TN + FP + FN}
    \end{equation}
    其中TN是真负例（正确识别的正常样本）。
\end{enumerate}

\subsubsection{排序评估指标}

\begin{enumerate}
    \item \textbf{ROC曲线和AUC-ROC}：
    \begin{itemize}
        \item ROC曲线展示了在不同阈值下真阳性率（TPR）和假阳性率（FPR）之间的权衡
        \item AUC-ROC是ROC曲线下的面积，取值范围为$[0.5, 1]$，越接近1表示性能越好
    \end{itemize}
    
    \item \textbf{PR曲线和AUC-PR}：
    \begin{itemize}
        \item PR曲线展示了精确率和召回率之间的关系
        \item AUC-PR是PR曲线下的面积，在不平衡数据集上比AUC-ROC更有信息量
    \end{itemize}
\end{enumerate}

\subsubsection{可视化评估}

\begin{enumerate}
    \item \textbf{混淆矩阵}：直观展示模型的分类结果
    \item \textbf{重构误差分布}：比较正常样本和异常样本的重构误差分布
    \item \textbf{错误分类样本}：分析模型错误分类的样本，了解模型的弱点
\end{enumerate}

\subsection{实验结果}

\subsubsection{模型性能对比}

我们比较了不同模型在两个类别上的性能：

\begin{table}[H]
\centering
\caption{不同模型在hazelnut类别上的性能}
\label{tab:hazelnut_results}
\begin{tabular}{lccccc}
\toprule
\textbf{模型} & \textbf{AUC-ROC} & \textbf{AUC-PR} & \textbf{精确率} & \textbf{召回率} & \textbf{F1分数} \\ 
\midrule
Autoencoder & 0.XXXX & 0.XXXX & 0.XXXX & 0.XXXX & 0.XXXX \\ 
VAE & 0.XXXX & 0.XXXX & 0.XXXX & 0.XXXX & 0.XXXX \\ 
\bottomrule
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\caption{不同模型在zipper类别上的性能}
\label{tab:zipper_results}
\begin{tabular}{lccccc}
\toprule
\textbf{模型} & \textbf{AUC-ROC} & \textbf{AUC-PR} & \textbf{精确率} & \textbf{召回率} & \textbf{F1分数} \\ 
\midrule
Autoencoder & 0.XXXX & 0.XXXX & 0.XXXX & 0.XXXX & 0.XXXX \\ 
VAE & 0.XXXX & 0.XXXX & 0.XXXX & 0.XXXX & 0.XXXX \\ 
\bottomrule
\end{tabular}
\end{table}

\subsubsection{重构误差分布}

图\ref{fig:error_dist}展示了正常样本和异常样本的重构误差分布：

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{results/error_distribution.png}
\caption{重构误差分布对比}
\label{fig:error_dist}
\end{figure}

\subsubsection{ROC曲线}

图\ref{fig:roc_curve}展示了模型的ROC曲线：

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{results/roc_curve.png}
\caption{ROC曲线对比}
\label{fig:roc_curve}
\end{figure}

\subsection{结果分析}

根据实验结果，我们可以得出以下结论：

\begin{enumerate}
    \item \textbf{模型比较}：
    \begin{itemize}
        \item VAE在某些指标上可能优于基础Autoencoder，因为它引入了概率建模
        \item 然而，对于简单的异常检测任务，基础Autoencoder可能已经足够，且训练更稳定
    \end{itemize}
    
    \item \textbf{类别差异}：
    \begin{itemize}
        \item 不同类别的异常检测性能可能有所不同
        \item 这可能与异常的类型、程度以及正常样本的多样性有关
    \end{itemize}
    
    \item \textbf{阈值选择}：
    \begin{itemize}
        \item 阈值的选择对精确率和召回率有显著影响
        \item 可以根据具体应用场景的需求来调整阈值
    \end{itemize}
    
    \item \textbf{重构误差特性}：
    \begin{itemize}
        \item 异常样本通常具有更高的重构误差
        \item 但正常样本和异常样本的重构误差分布可能存在重叠，这给检测带来挑战
    \end{itemize}
\end{enumerate}

\section{总结}

\subsection{主要贡献}

本报告完成了图像异常检测任务，主要贡献包括：

\begin{enumerate}
    \item \textbf{问题形式化}：将图像异常检测问题转化为基于重构误差的二分类问题，并给出了数学描述。
    
    \item \textbf{模型实现}：实现了两种自编码器模型（基础自编码器和变分自编码器）用于异常检测。
    
    \item \textbf{评估方法}：使用多种评估指标（AUC-ROC、AUC-PR、精确率、召回率、F1分数等）全面评估了模型性能。
    
    \item \textbf{实验分析}：通过实验比较了不同模型在不同类别上的性能，并分析了重构误差的分布特性。
\end{enumerate}

\subsection{主要发现}

\begin{enumerate}
    \item 自编码器是一种有效的图像异常检测方法，特别是当训练数据主要包含正常样本时。
    \item 重构误差是一个简单但有效的异常分数，可以很好地区分正常样本和异常样本。
    \item 阈值的选择对异常检测性能有重要影响，需要根据具体应用场景进行调整。
    \item 变分自编码器通过引入概率建模，可以提供更丰富的潜在表示，但训练复杂度更高。
\end{enumerate}

\subsection{未来改进方向}

\begin{enumerate}
    \item \textbf{模型改进}：
    \begin{itemize}
        \item 尝试更复杂的网络结构，如U-Net或Transformer
        \item 探索基于生成对抗网络（GAN）的异常检测方法
        \item 考虑使用预训练模型进行特征提取
    \end{itemize}
    
    \item \textbf{异常分数改进}：
    \begin{itemize}
        \item 结合多种异常分数，如重构误差和潜在空间距离
        \item 探索基于密度估计的异常分数
    \end{itemize}
    
    \item \textbf{数据增强}：
    \begin{itemize}
        \item 设计更有效的数据增强策略，提高模型的泛化能力
        \item 考虑使用自监督学习方法增强特征学习
    \end{itemize}
    
    \item \textbf{阈值优化}：
    \begin{itemize}
        \item 开发自适应阈值选择方法
        \item 考虑基于验证集的动态阈值调整
    \end{itemize}
\end{enumerate}

\section{参考文献}

\begin{enumerate}
    \item Vincent, P., et al. (2008). Extracting and composing robust features with denoising autoencoders.
    \item Kingma, D. P., & Welling, M. (2013). Auto-encoding variational bayes.
    \item Goodfellow, I., et al. (2014). Generative adversarial nets.
    \item Schölkopf, B., et al. (2001). Estimating the support of a high-dimensional distribution.
    \item Ruff, L., et al. (2021). Deep one-class classification.
    \item Chalapathy, R., & Chawla, S. (2019). Deep learning for anomaly detection: A survey.
\end{enumerate}

\end{document}